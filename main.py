from fastapi import FastAPI, Request, HTTPException
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError, LineBotApiError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
import openai
import os
import uvicorn
import logging
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

LINE_CHANNEL_ACCESS_TOKEN = os.getenv('LINE_CHANNEL_ACCESS_TOKEN')
LINE_CHANNEL_SECRET = os.getenv('LINE_CHANNEL_SECRET')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)
client = openai.OpenAI(api_key=OPENAI_API_KEY)

app = FastAPI()
user_responses = {}

# è³ªå•å®šç¾©ï¼ˆçœç•¥ï¼‰
QUESTIONS = {
    1: {"question": "ğŸ¤” **è³ªå•1/10ã€èªçŸ¥æ§‹é€ ã€‘**\n\næœ€è¿‘ã€é‡è¦ãªæ±ºæ–­ã‚’ã—ãŸä½“é¨“ã«ã¤ã„ã¦ã€ãã®æ™‚ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’å…·ä½“çš„ã«æ•™ãˆã¦ãã ã•ã„ã€‚", "example": "ğŸ’ª è©³ã—ãæ›¸ãã»ã©ç²¾å¯†ï¼"},
    2: {"question": "ğŸ“š **è³ªå•2/10ã€èªçŸ¥æ§‹é€ ã€‘**\n\næ–°ã—ã„ã“ã¨ã‚’å­¦ã¶ã¨ãã€ã©ã‚“ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å–ã‚Šã¾ã™ã‹ï¼Ÿ", "example": "ğŸ’ª è©³ã—ãæ›¸ãã»ã©ç²¾å¯†ï¼"},
    3: {"question": "ğŸ˜° **è³ªå•3/10ã€æ„Ÿæƒ…æ§‹é€ ã€‘**\n\nã‚¹ãƒˆãƒ¬ã‚¹ã‚„å›°é›£ãªçŠ¶æ³ã«ç›´é¢ã—ãŸã¨ãã€ã©ã‚“ãªæ„Ÿæƒ…ãŒæ¹§ãã€ã©ã†å¯¾å‡¦ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ", "example": "ğŸ’ª è©³ã—ãæ›¸ãã»ã©ç²¾å¯†ï¼"},
    4: {"question": "âœ¨ **è³ªå•4/10ã€æ„Ÿæƒ…æ§‹é€ ã€‘**\n\nã‚ãªãŸãŒæœ€ã‚‚å……å®Ÿæ„Ÿã‚„å–œã³ã‚’æ„Ÿã˜ã‚‹ç¬é–“ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚", "example": "ğŸ’ª è©³ã—ãæ›¸ãã»ã©ç²¾å¯†ï¼"},
    5: {"question": "ğŸ‘¥ **è³ªå•5/10ã€è¡Œå‹•æ§‹é€ ã€‘**\n\näººé–“é–¢ä¿‚ã§å›°ã£ãŸçµŒé¨“ã«ã¤ã„ã¦ã€ãã®æ™‚ã®çŠ¶æ³ã¨è¡Œå‹•ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚", "example": "ğŸ’ª è©³ã—ãæ›¸ãã»ã©ç²¾å¯†ï¼"},
    6: {"question": "ğŸ¯ **è³ªå•6/10ã€ä¾¡å€¤è¦³æ§‹é€ ã€‘**\n\nã‚ãªãŸãŒã€Œã“ã‚Œã ã‘ã¯è­²ã‚Œãªã„ã€ã¨æ€ã†ã“ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ", "example": "ğŸ’ª è©³ã—ãæ›¸ãã»ã©ç²¾å¯†ï¼"},
    7: {"question": "ğŸŒŸ **è³ªå•7/10ã€ä¾¡å€¤è¦³æ§‹é€ ã€‘**\n\näººç”Ÿã§æœ€ã‚‚å¤§åˆ‡ã«ã—ãŸã„ä¾¡å€¤è¦³ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚", "example": "ğŸ’ª è©³ã—ãæ›¸ãã»ã©ç²¾å¯†ï¼"},
    8: {"question": "ğŸš€ **è³ªå•8/10ã€è‡ªå·±ç‰©èªã€‘**\n\n5å¹´å¾Œã€ã©ã‚“ãªè‡ªåˆ†ã«ãªã£ã¦ã„ãŸã„ã§ã™ã‹ï¼Ÿ", "example": "ğŸ’ª è©³ã—ãæ›¸ãã»ã©ç²¾å¯†ï¼"},
    9: {"question": "â° **è³ªå•9/10ã€æ™‚é–“è»¸æ§‹é€ ã€‘**\n\néå»ã®è‡ªåˆ†ã¨æ¯”ã¹ã¦ã€ä»Šã„ã¡ã°ã‚“å¤‰ã‚ã£ãŸã¨æ€ã†ç‚¹ã¯ï¼Ÿ", "example": "ğŸ’ª è©³ã—ãæ›¸ãã»ã©ç²¾å¯†ï¼"},
    10: {"question": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **è³ªå•10/10ã€ä»–è€…è¦–ç‚¹æ§‹é€ ã€‘**\n\nè¦ªã—ã„å‹äººãŒã‚ãªãŸã‚’ç´¹ä»‹ã™ã‚‹ã¨ãã€ä½•ã¨è¨€ã†ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ", "example": "ğŸ’ª è©³ã—ãæ›¸ãã»ã©ç²¾å¯†ï¼"}
}

@app.post("/callback")
async def callback(request: Request):
    signature = request.headers.get('X-Line-Signature', '')
    body = await request.body()
    try:
        handler.handle(body.decode('utf-8'), signature)
    except InvalidSignatureError:
        raise HTTPException(status_code=400, detail="Invalid signature")
    return {"status": "ok"}

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    try:
        user_id = event.source.user_id
        user_message = event.message.text.strip()
        
        if user_id not in user_responses:
            user_responses[user_id] = {"current_question": 0, "answers": {}, "completed": False}
        
        user_data = user_responses[user_id]
        
        if user_message in ["è¨ºæ–­", "start", "é–‹å§‹", "è¨ºæ–­é–‹å§‹"] or user_data["current_question"] == 0:
            start_diagnosis(user_id, event.reply_token)
            return
        
        if user_data["completed"]:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="è¨ºæ–­å®Œäº†æ¸ˆã¿ã€‚æ–°ã—ã„è¨ºæ–­ã¯ã€Œè¨ºæ–­é–‹å§‹ã€"))
            return
        
        if user_data["current_question"] > 0:
            process_answer(user_id, user_message, event.reply_token)
    except Exception as e:
        logger.error(f"Error in handle_message: {e}", exc_info=True)

def start_diagnosis(user_id, reply_token):
    try:
        user_responses[user_id] = {"current_question": 1, "answers": {}, "completed": False}
        welcome = "ğŸ¯ AIãƒ‘ãƒ¼ã‚½ãƒŠãƒ«è¨ºæ–­ã¸ã‚ˆã†ã“ãï¼\n10ã®è³ªå•ã§å®Œå…¨å€‹åˆ¥åŒ–ã•ã‚ŒãŸæ€§æ ¼åˆ†æã‚’è¡Œã„ã¾ã™ã€‚"
        line_bot_api.reply_message(reply_token, TextSendMessage(text=welcome))
        send_question(user_id, 1)
    except Exception as e:
        logger.error(f"Error in start_diagnosis: {e}", exc_info=True)

def send_question(user_id, question_num):
    try:
        if question_num > 10:
            return
        q = QUESTIONS[question_num]
        line_bot_api.push_message(user_id, TextSendMessage(text=q["question"]))
        line_bot_api.push_message(user_id, TextSendMessage(text=q["example"]))
    except Exception as e:
        logger.error(f"Error in send_question: {e}", exc_info=True)

def process_answer(user_id, answer, reply_token):
    try:
        user_data = user_responses[user_id]
        current_q = user_data["current_question"]
        user_data["answers"][current_q] = answer
        
        if current_q < 10:
            user_data["current_question"] = current_q + 1
            line_bot_api.reply_message(reply_token, TextSendMessage(text=f"âœ… å›ç­”ã‚ã‚ŠãŒã¨ã†ï¼ç¶šã„ã¦è³ªå•{current_q + 1}ã§ã™ã€‚"))
            send_question(user_id, current_q + 1)
        else:
            user_data["completed"] = True
            line_bot_api.reply_message(reply_token, TextSendMessage(text="ğŸ‰ å…¨è³ªå•å®Œäº†ï¼åˆ†æä¸­..."))
            diagnosis = analyze_responses(user_data["answers"])
            send_diagnosis_result(user_id, diagnosis)
    except Exception as e:
        logger.error(f"Error in process_answer: {e}", exc_info=True)

def analyze_responses(answers):
    """GPT-5-miniå¯¾å¿œç‰ˆ - å¼·åŒ–ãƒ‡ãƒãƒƒã‚° + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        responses_text = "\n\n".join([f"è³ªå•{q}: {a}" for q, a in answers.items()])
        logger.info(f"[DEBUG] Analysis start. Input length: {len(responses_text)} chars")
        
        # ã‚·ãƒ³ãƒ—ãƒ«åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ï¼‰
        system_prompt = """You are an expert psychologist. Respond in Japanese.

CRITICAL RULES:
- Write in "ã‚ãªãŸã¯ã€œã™ã‚‹" format (action-oriented)
- NO abstract analysis phrases like "å‚¾å‘ãŒã‚ã‚Šã¾ã™", "ç¤ºã—ã¦ã„ã¾ã™"
- Use concrete daily life scenes (150+ chars per section)
- Structure: Psychology â†’ Behavior â†’ Emotion

OUTPUT FORMAT:
ğŸ¯ è¨ºæ–­å®Œäº†ï¼

## ğŸ­ ã€Œ[ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ]ã€

### ğŸ’« æ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³
[å¿ƒç†æ§‹é€  50æ–‡å­—]
â†’ [æ—¥å¸¸ã‚·ãƒ¼ãƒ³ 150æ–‡å­—]
[æ„Ÿæƒ… 50æ–‡å­—]

### ğŸ’ æ„Ÿæƒ…ã®å‹•ã
[å¿ƒç†æ§‹é€  50æ–‡å­—]
â†’ [æ—¥å¸¸ã‚·ãƒ¼ãƒ³ 150æ–‡å­—]
[è¡Œå‹•ã¸ã®å½±éŸ¿ 50æ–‡å­—]

### ğŸŒŸ å¤§åˆ‡ã«ã—ã¦ã„ã‚‹ã‚‚ã®
[ä¾¡å€¤è¦³ 50æ–‡å­—]
â†’ [æ—¥å¸¸ã‚·ãƒ¼ãƒ³ 150æ–‡å­—]
[èƒŒæ™¯ 50æ–‡å­—]

### ğŸ’ª å¼·ã¿Top3
1. **[åå‰]**: [èƒŒæ™¯ 40æ–‡å­—]
â†’ [æ—¥å¸¸ã‚·ãƒ¼ãƒ³ 180æ–‡å­—]

2. **[åå‰]**: [èƒŒæ™¯ 40æ–‡å­—]
â†’ [æ—¥å¸¸ã‚·ãƒ¼ãƒ³ 180æ–‡å­—]

3. **[åå‰]**: [èƒŒæ™¯ 40æ–‡å­—]
â†’ [æ—¥å¸¸ã‚·ãƒ¼ãƒ³ 180æ–‡å­—]

### âš ï¸ æ°—ã‚’ã¤ã‘ãŸã„ã“ã¨Top3
1. **[åå‰]**: [ãƒ¡ã‚«ãƒ‹ã‚ºãƒ  40æ–‡å­—]
â†’ [æ—¥å¸¸ã‚·ãƒ¼ãƒ³ 180æ–‡å­—]

2. **[åå‰]**: [ãƒ¡ã‚«ãƒ‹ã‚ºãƒ  40æ–‡å­—]
â†’ [æ—¥å¸¸ã‚·ãƒ¼ãƒ³ 180æ–‡å­—]

3. **[åå‰]**: [ãƒ¡ã‚«ãƒ‹ã‚ºãƒ  40æ–‡å­—]
â†’ [æ—¥å¸¸ã‚·ãƒ¼ãƒ³ 180æ–‡å­—]

### ğŸ’¡ æ´»ã‹ã—æ–¹
#### ğŸ§© ä»•äº‹ã§
[150æ–‡å­—]

#### ğŸ’ æ‹æ„›ã§
[150æ–‡å­—]

#### ğŸ§‘â€ğŸ¤â€ğŸ§‘ äººé–“é–¢ä¿‚ã§
[150æ–‡å­—]"""

        analysis_prompt = f"""ä»¥ä¸‹ã®10å•ã®å›ç­”ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š

{responses_text}

INSTRUCTIONS:
- ç¦æ­¢è¡¨ç¾ã‚’ä½¿ã‚ãšè¡Œå‹•æå†™ã§æ›¸ã
- å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«å…·ä½“çš„æ—¥å¸¸ã‚·ãƒ¼ãƒ³ã‚’å«ã‚ã‚‹
- æ–‡å­—æ•°è¦ä»¶ã‚’å®ˆã‚‹
- ã“ã®äººå›ºæœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": analysis_prompt}
        ]

        logger.info("[DEBUG] Calling OpenAI API with GPT-5-mini...")
        
        try:
            response = client.chat.completions.create(
                model="gpt-5-mini",
                messages=messages,
                max_completion_tokens=3500  # 4500â†’3500ã«å‰Šæ¸›
            )
            
            logger.info(f"[DEBUG] API call successful. Response type: {type(response)}")
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ã®è©³ç´°ç¢ºèª
            if not response.choices:
                logger.error("[ERROR] response.choices is empty")
                return generate_fallback_diagnosis(answers)
            
            message_content = response.choices[0].message.content
            logger.info(f"[DEBUG] message.content type: {type(message_content)}, value: {message_content[:100] if message_content else 'None'}")
            
            if not message_content:
                logger.error("[ERROR] message.content is None or empty")
                return generate_fallback_diagnosis(answers)
            
            result = message_content.strip()
            
            if len(result) < 100:
                logger.warning(f"[WARNING] Result too short: {len(result)} chars")
                return generate_fallback_diagnosis(answers)
            
            logger.info(f"[SUCCESS] Analysis completed! Length: {len(result)} chars")
            return result
            
        except openai.APIError as api_err:
            logger.error(f"[ERROR] OpenAI API Error: {api_err}", exc_info=True)
            return generate_fallback_diagnosis(answers)
        except Exception as api_ex:
            logger.error(f"[ERROR] Unexpected API error: {api_ex}", exc_info=True)
            return generate_fallback_diagnosis(answers)

    except Exception as e:
        logger.error(f"[CRITICAL ERROR] analyze_responses failed: {e}", exc_info=True)
        return generate_fallback_diagnosis(answers)

def generate_fallback_diagnosis(answers):
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨ºæ–­ï¼ˆGPT-4o-miniã§å†è©¦è¡Œï¼‰"""
    try:
        logger.info("[FALLBACK] Trying GPT-4o-mini as fallback...")
        
        responses_text = "\n\n".join([f"è³ªå•{q}: {a}" for q, a in answers.items()])
        
        simple_prompt = f"""ä»¥ä¸‹ã®10å•ã®å›ç­”ã‹ã‚‰ã€ã“ã®äººã®æ€§æ ¼ã‚’æ—¥æœ¬èªã§è¨ºæ–­ã—ã¦ãã ã•ã„ã€‚
å¿…ãšã€Œã‚ãªãŸã¯ã€œã™ã‚‹ã€å½¢å¼ã§ã€å…·ä½“çš„ãªæ—¥å¸¸è¡Œå‹•ã‚’æå†™ã—ã¦ãã ã•ã„ã€‚

{responses_text}

è¨ºæ–­çµæœï¼ˆ1500æ–‡å­—ä»¥ä¸Šã§è©³ã—ãï¼‰ï¼š"""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": simple_prompt}],
            max_completion_tokens=2000,
            temperature=0.8
        )
        
        result = response.choices[0].message.content or ""
        
        if result and len(result) > 100:
            logger.info(f"[FALLBACK SUCCESS] GPT-4o-mini diagnosis: {len(result)} chars")
            return f"ğŸ¯ è¨ºæ–­å®Œäº†ï¼\n\n{result}\n\nâ€» GPT-4o-miniã§ç”Ÿæˆã•ã‚Œã¾ã—ãŸ"
        else:
            logger.error("[FALLBACK FAILED] GPT-4o-mini also returned empty")
            return generate_emergency_diagnosis()
            
    except Exception as fb_err:
        logger.error(f"[FALLBACK ERROR] {fb_err}", exc_info=True)
        return generate_emergency_diagnosis()

def generate_emergency_diagnosis():
    """ç·Šæ€¥æ™‚ã®å›ºå®šè¨ºæ–­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
    return """ğŸ¯ è¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ ä¸€æ™‚åœæ­¢ä¸­

ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ç¾åœ¨è¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ ã«æŠ€è¡“çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚

ğŸ“§ ã‚µãƒãƒ¼ãƒˆã«è‡ªå‹•é€šçŸ¥æ¸ˆã¿
ğŸ”„ ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰ã€Œè¨ºæ–­é–‹å§‹ã€ã§å†è©¦è¡Œã—ã¦ãã ã•ã„

ã”ä¸ä¾¿ã‚’ãŠã‹ã‘ã—ã¦ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚"""

def send_diagnosis_result(user_id, diagnosis_result):
    try:
        logger.info(f"[DEBUG] Sending diagnosis. Length: {len(diagnosis_result)}, Empty: {not diagnosis_result.strip()}")
        
        # ç©ºãƒã‚§ãƒƒã‚¯å¼·åŒ–
        if not diagnosis_result or not diagnosis_result.strip():
            logger.error("[ERROR] diagnosis_result is empty!")
            diagnosis_result = generate_emergency_diagnosis()
        
        max_length = 5000
        if len(diagnosis_result) <= max_length:
            line_bot_api.push_message(user_id, TextSendMessage(text=diagnosis_result))
        else:
            parts = []
            current = ""
            for line in diagnosis_result.split('\n'):
                if len(current + line + '\n') <= max_length:
                    current += line + '\n'
                else:
                    if current:
                        parts.append(current)
                    current = line + '\n'
            if current:
                parts.append(current)
            
            for i, part in enumerate(parts):
                logger.info(f"[DEBUG] Sending part {i+1}/{len(parts)}, length: {len(part)}")
                line_bot_api.push_message(user_id, TextSendMessage(text=part))
        
        line_bot_api.push_message(user_id, TextSendMessage(text="ğŸ‰ è¨ºæ–­å®Œäº†ï¼\n\nğŸ”„ æ–°ã—ã„è¨ºæ–­: ã€Œè¨ºæ–­é–‹å§‹ã€\nğŸ“¤ å‹é”ã«ã‚‚ã‚·ã‚§ã‚¢æ¨å¥¨ï¼"))
        logger.info(f"[SUCCESS] Result sent successfully")
    except LineBotApiError as line_err:
        logger.error(f"[ERROR] LINE API Error: {line_err}", exc_info=True)
    except Exception as e:
        logger.error(f"[ERROR] send_diagnosis_result failed: {e}", exc_info=True)

@app.get("/")
async def root():
    return {"status": "ok", "message": "AI Diagnosis Bot Running (GPT-5-mini with fallback)"}

@app.get("/health")
async def health():
    return {"status": "ok", "line": bool(LINE_CHANNEL_ACCESS_TOKEN), "openai": bool(OPENAI_API_KEY)}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
